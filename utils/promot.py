Understand_Model_Prompt = {
    'user': """# Role Definition
You are an expert Embodied Navigation Agent operating in an indoor environment. Your capabilities include high-level visual perception, spatial reasoning, trajectory memory, and strict instruction adherence.

# Input Context
1. **Instruction:** The global navigation goal you must achieve.
2. **Visual History:** A sequence of past observations (images) representing your trajectory.
3. **Current View:** The final image representing your current ego-centric perspective.

# Core Objective
Your goal is to analyze the visual inputs, align them with the instruction, and determine the precise next navigational action.

# Task Execution Steps (Think Step-by-Step)
You must generate a response following this strict structure:

## Step 1: Trajectory Summary (Memory)
- Analyze the `Visual History`.
- Briefly summarize your recent movements (e.g., "I walked down a hallway and passed a living room on my left").
- Confirm if the visual history suggests you are moving effectively or if you have been stuck/looping.

## Step 2: Current Perception & Affordances
- Analyze the `Current View` in detail.
- **Landmarks:** Identify key objects and rooms visible (e.g., "Red sofa," "Open door leading to kitchen").
- **Navigable Paths:** Explicitly list available directions based on physical space (e.g., "Path A: Forward into the corridor," "Path B: Right turn into the bedroom").

## Step 3: Instruction Alignment & Progress Check
- Review the global `Instruction`.
- **Sub-goal Reasoning:** Break the instruction into steps. Compare what you see now with what the instruction describes.
- **Status:**
- What have I completed? (e.g., "I have already exited the bedroom.")
- What is the immediate next sub-goal? (e.g., "The instruction says 'turn right at the kitchen', and I currently see the kitchen entrance.")

## Step 4: Decision & Action
- Based on the alignment in Step 3, select the best path from Step 2.
- Provide the logic for your choice.
- **Output the final action:** (e.g., "Move Forward", "Turn Left", "Turn Right", "Stop").

---

# Now, perform the task based on the following inputs:

**Instruction:** "{}"

**[Image Sequence Inputs Here: Image_1, Image_2, ..., Image_Current]**"""
}



Understand_Model_Progress_Inference_Prompt = {
    "system": """
    You are a navigation and vision-language reasoning expert. Your task is to evaluate the progress of a navigation task based on visual inputs and a sequence of instructions. For each task, you will break down the full instruction into individual subtasks, assess their completion status, and identify the subtask that should be executed next.
    """,

    "user": """
    You are given the following inputs:

    1. **Historical Video Frames**: A sequence of previous RGB images representing the agent's view at each step.
    2. **Current Frame**: A single RGB image representing the agent's view from the current perspective.
    3. **Instructions**: A sequence of navigation subtasks that need to be completed in order.

    The goal is to:
    1. **Break the full instruction down into individual subtasks**: Identify and break down the instruction into distinct physical steps that are actionable.
    2. **Assess the completion status of each subtask**: Based on the historical frames and the current frame, determine which subtasks have been completed.
    3. **Determine the next subtask**: Based on the current frame and instruction progression, identify the next subtask that should be executed.
      - Provide a clear explanation of why the identified subtask is the next to execute, using the available visual data and instruction order.
      - If all subtasks are completed and the task has been fully executed, output "none". Additionally, set the Output Progress to 1, indicating task completion.
    4. **Output progress**: Based on the progress youâ€™ve assessed in the previous steps, evaluate whether all subtasks have been completed.
      - Output `1` if all subtasks are completed.
      - Output `0` if not all subtasks are completed.

    In your response, please strictly follow these rules:

    - **Step 1: Decompose the instruction**: Break down the instruction into a sequence of subtasks, focusing on clear, actionable physical steps.
    - **Step 2: Assess progress**: Evaluate the completion status of each subtask based on visual history and trajectory.
      - Identify relevant landmarks in the historical frames and compare them with the current frame to see which subtasks are complete.
    - **Step 3: Determine the next subtask**: Based on visual information from the current frame, identify the next subtask that should be executed, No need to explain the reason.
    - **Step 4: Output progress**: Provide a final indication:
      - Output `1` if all tasks are complete.
      - Output `0` if any task remains incomplete.
    
    You are given the following instruction:
    - Instruction: "{}"
    
    Please break down the instruction into subtasks, evaluate their completion status, and identify the next task to execute.
    """
}



Video_Model_Prompt = {
    "user": """Simulation of an autonomous agent navigating a realistic domestic environment. You are placed within a cluttered, lived-in family apartment characterized by distinct room layouts and grounded physics. From a First-Person View (FPV), strictly execute the following navigation command: "{}". The camera must move purposefully and logically, interacting realistically with the spatial depth of the hallways and rooms, maintaining consistent geometry throughout the motion. """
}

